{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myadix\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import wandb\n",
    "from transformers import ViTMAEConfig\n",
    "\n",
    "from custom_models.CustomViT import CustomViT\n",
    "from custom_models.CustomViTMAE import CustomViTMAE\n",
    "from transformers.models.vit_mae.modeling_vit_mae import ViTMAEModel\n",
    "# from tem_dataloader import MultimodalDatasetPerTrajectory\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from d3rlpy.algos import CQL\n",
    "from d3rlpy.dataset import Episode, MDPDataset, Transition\n",
    "wandb.login() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_models.CustomViT import CustomViT\n",
    "from custom_models.CustomViTMAE import CustomViTMAE\n",
    "import torch\n",
    "# call CustomViT\n",
    "from transformers import AutoImageProcessor, ViTMAEForPreTraining, ViTMAEConfig\n",
    "from PIL import Image\n",
    "\n",
    "# output_dir='/home/tyz/Desktop/11_777/camelmera/weights'\n",
    "trained_model_name = 'multimodal'\n",
    "output_dir='/home/ubuntu/weights/' + trained_model_name\n",
    "\n",
    "# Initialize a new CustomViT model\n",
    "model_name = \"facebook/vit-mae-base\"\n",
    "vit_config = ViTMAEConfig.from_pretrained(model_name)\n",
    "vit_config.output_hidden_states=True\n",
    "vit_model = CustomViT(config=vit_config)\n",
    "\n",
    "# Initialize a new CustomViTMAE model\n",
    "model_name = \"facebook/vit-mae-base\"\n",
    "config = ViTMAEConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states=True\n",
    "custom_model = CustomViTMAE(config=config)\n",
    "custom_model.vit = vit_model\n",
    "\n",
    "# Load the state_dict from the saved model\n",
    "state_dict = torch.load(f\"{output_dir}/pytorch_model.bin\")\n",
    "custom_model.load_state_dict(state_dict)\n",
    "\n",
    "# don't need decoders\n",
    "vit_encoder = custom_model.vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P001\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P004\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P006\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P005\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P008\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P002\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P009\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P003\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P000\n",
      "Number of images: 8185\n",
      "Number of depth: 8185\n",
      "Number of lidar: 8185\n"
     ]
    }
   ],
   "source": [
    "from tem_dataloader import MultimodalDataset\n",
    "import functools\n",
    "\n",
    "environment_name = 'AbandonedFactoryExposure'\n",
    "environemnt_directory = f'/mnt/data/tartanairv2filtered/{environment_name}/Data_easy'\n",
    "dataset = MultimodalDataset(environemnt_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P000\n",
      "Number of images: 1480\n",
      "Number of depth: 1480\n",
      "Number of lidar: 1480\n",
      "Number of pose: 1480\n",
      "All observations shape: (8, 768)\n",
      "All actions shape: (8, 7)\n",
      "All rewards shape: (8,)\n",
      "All terminals shape: (8,)\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P001\n",
      "Number of images: 1055\n",
      "Number of depth: 1055\n",
      "Number of lidar: 1055\n",
      "Number of pose: 1055\n",
      "All observations shape: (31, 768)\n",
      "All actions shape: (31, 7)\n",
      "All rewards shape: (31,)\n",
      "All terminals shape: (31,)\n",
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P002\n",
      "Number of images: 698\n",
      "Number of depth: 698\n",
      "Number of lidar: 698\n",
      "Number of pose: 698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m all_rewards \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m all_terminals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     26\u001b[0m     \u001b[39m# get embedding\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     vit_encoder\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     28\u001b[0m     vit_encoder\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/camelmera/models/gym/multimodal/tem_dataloader.py:215\u001b[0m, in \u001b[0;36mMultimodalDatasetPerTrajectory.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m# read the lidar from disk\u001b[39;00m\n\u001b[1;32m    214\u001b[0m lidar_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlidar_paths[index]\n\u001b[0;32m--> 215\u001b[0m lidar \u001b[39m=\u001b[39m process_lidar(lidar_path)\n\u001b[1;32m    217\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    218\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m: image,\n\u001b[1;32m    219\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpixel_values1\u001b[39m\u001b[39m\"\u001b[39m: depth,\n\u001b[1;32m    220\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpixel_values2\u001b[39m\u001b[39m\"\u001b[39m: lidar,\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpose_values\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpose[index]\n\u001b[1;32m    222\u001b[0m }\n",
      "File \u001b[0;32m~/camelmera/models/gym/multimodal/tem_dataloader.py:56\u001b[0m, in \u001b[0;36mprocess_lidar\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         voxel_points \u001b[39m=\u001b[39m points[voxel_indices]\n\u001b[1;32m     55\u001b[0m         feature \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(\n\u001b[0;32m---> 56\u001b[0m             [np\u001b[39m.\u001b[39;49mmean(voxel_points[:, :\u001b[39m3\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), np\u001b[39m.\u001b[39mmax(voxel_points[:, :\u001b[39m3\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)])\n\u001b[1;32m     57\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n\u001b[1;32m     58\u001b[0m features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(features)\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tem_dataloader import MultimodalDatasetPerTrajectory\n",
    "import functools\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "environment_name = 'AbandonedFactoryExposure'\n",
    "environemnt_directory = f'/mnt/data/tartanairv2filtered/{environment_name}/Data_easy'\n",
    "OBSERVATION_SIZE = 768\n",
    "ACTION_SIZE = 7\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for i in range(0,10):\n",
    "    if i==7:\n",
    "        continue\n",
    "    trajectory_folder_path = os.path.join(environemnt_directory, f'P00{i}')\n",
    "    my_dataset = MultimodalDatasetPerTrajectory(trajectory_folder_path)\n",
    "    train_dataloader = DataLoader(my_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize empty arrays for observations, actions, rewards, and terminals\n",
    "    all_observations = np.empty((0, OBSERVATION_SIZE))\n",
    "    all_actions = np.empty((0, ACTION_SIZE))\n",
    "    all_rewards = np.empty(0)\n",
    "    all_terminals = np.empty(0, dtype=bool)\n",
    "\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        # get embedding\n",
    "        vit_encoder.cuda()\n",
    "        vit_encoder.eval()\n",
    "        pixel_values = data[\"pixel_values\"].cuda()\n",
    "        pixel_values1 = data[\"pixel_values1\"].cuda()\n",
    "        pixel_values2 = data[\"pixel_values2\"].cuda()\n",
    "        outputs = vit_encoder(pixel_values,pixel_values1,pixel_values2,noise=None)\n",
    "        embedding = outputs.last_hidden_state[:,0,:]\n",
    "        observation = embedding.cpu().detach().numpy()\n",
    "        # get action\n",
    "        pose = data[\"pose_values\"]\n",
    "        action = torch.diff(pose,axis = 0).numpy()\n",
    "        action = np.concatenate((action, np.zeros((1,7))), axis=0)\n",
    "        # get reward\n",
    "        goal = observation[-1]\n",
    "        partial_function = functools.partial(reward_function, goal_embedding=goal)\n",
    "        reward = np.apply_along_axis(partial_function, 1, observation)\n",
    "        # get terminals\n",
    "        terminals = np.zeros_like(reward, dtype=int)\n",
    "        terminals[reward == 100] = 1\n",
    "\n",
    "        # Concatenate observations, actions, rewards, and terminals\n",
    "        all_observations = np.vstack((all_observations, observation))\n",
    "        all_actions = np.vstack((all_actions, action))\n",
    "        all_rewards = np.hstack((all_rewards, reward))\n",
    "        all_terminals = np.hstack((all_terminals, terminals))\n",
    "\n",
    "    print(\"All observations shape:\", all_observations.shape)\n",
    "    print(\"All actions shape:\", all_actions.shape)\n",
    "    print(\"All rewards shape:\", all_rewards.shape)\n",
    "    print(\"All terminals shape:\", all_terminals.shape)\n",
    "    \n",
    "    np.save(f'trajectories/all_observations_P00{i}.npy', all_observations)\n",
    "    np.save(f'trajectories/all_actions_P00{i}.npy', all_actions)\n",
    "    np.save(f'trajectories/all_rewards_P00{i}.npy', all_rewards)\n",
    "    np.save(f'trajectories/all_terminals_P00{i}.npy', all_terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: /mnt/data/tartanairv2filtered/AbandonedFactoryExposure/Data_easy/P000\n",
      "Number of images: 1480\n",
      "Number of depth: 1480\n",
      "Number of lidar: 1480\n",
      "Number of pose: 1480\n"
     ]
    }
   ],
   "source": [
    "from tem_dataloader import MultimodalDatasetPerTrajectory\n",
    "# environment_name = 'AmericanDinerExposure'\n",
    "# environemnt_directory = f'/media/tyz/3B6FFE7354FF3296/11_777/tartanairv2filtered/{environment_name}/Data_easy'\n",
    "# my_dataset = MultimodalDatasetPerTrajectory(environemnt_directory)\n",
    "environment_name = 'AbandonedFactoryExposure'\n",
    "environemnt_directory = f'/mnt/data/tartanairv2filtered/{environment_name}/Data_easy'\n",
    "OBSERVATION_SIZE = 768\n",
    "ACTION_SIZE = 7\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# for folder in os.listdir(environemnt_directory):\n",
    "trajectory_folder_path = os.path.join(environemnt_directory, 'P000')\n",
    "my_dataset = MultimodalDatasetPerTrajectory(trajectory_folder_path)\n",
    "train_dataloader = DataLoader(my_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reward_function(state_embedding, goal_embedding, threshold=0.05, goal_reward=100):\n",
    "    distance = np.linalg.norm(state_embedding - goal_embedding)\n",
    "\n",
    "    if distance <= threshold:\n",
    "        # Give a large positive reward when the goal is reached\n",
    "        reward = goal_reward\n",
    "    else:\n",
    "        # Give a negative reward proportional to the distance otherwise\n",
    "        reward = -distance\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 768)\n",
      "(64, 7)\n",
      "(64,)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Initialize empty arrays for observations, actions, rewards, and terminals\n",
    "all_observations = np.empty((0, OBSERVATION_SIZE))\n",
    "all_actions = np.empty((0, ACTION_SIZE))\n",
    "all_rewards = np.empty(0)\n",
    "all_terminals = np.empty(0, dtype=bool)\n",
    "\n",
    "for batch_idx, data in enumerate(train_dataloader):\n",
    "    # get embedding\n",
    "    vit_encoder.cuda()\n",
    "    vit_encoder.eval()\n",
    "    pixel_values = data[\"pixel_values\"].cuda()\n",
    "    pixel_values1 = data[\"pixel_values1\"].cuda()\n",
    "    pixel_values2 = data[\"pixel_values2\"].cuda()\n",
    "    outputs = vit_encoder(pixel_values,pixel_values1,pixel_values2,noise=None)\n",
    "    embedding = outputs.last_hidden_state[:,0,:]\n",
    "    observation = embedding.cpu().detach().numpy()\n",
    "    # get action\n",
    "    pose = data[\"pose_values\"]\n",
    "    action = torch.diff(pose,axis = 0).numpy()\n",
    "    action = np.concatenate((action, np.zeros((1,7))), axis=0)\n",
    "    # get reward\n",
    "    goal = observation[-1]\n",
    "    partial_function = functools.partial(reward_function, goal_embedding=goal)\n",
    "    reward = np.apply_along_axis(partial_function, 1, observation)\n",
    "    # get terminals\n",
    "    terminals = [False]*BATCH_SIZE\n",
    "    terminals[-1]=True\n",
    "    terminals = np.array(terminals)\n",
    "    if batch_idx==0:\n",
    "        print(observation.shape)\n",
    "        print(action.shape)\n",
    "        print(reward.shape)\n",
    "        print(terminals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All observations shape: (1480, 768)\n",
      "All actions shape: (1480, 7)\n",
      "All rewards shape: (1480,)\n",
      "All terminals shape: (1536,)\n"
     ]
    }
   ],
   "source": [
    "print(\"All observations shape:\", all_observations.shape)\n",
    "print(\"All actions shape:\", all_actions.shape)\n",
    "print(\"All rewards shape:\", all_rewards.shape)\n",
    "print(\"All terminals shape:\", all_terminals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_observations_P000.npy', all_observations)\n",
    "np.save('all_actions_P000.npy', all_actions)\n",
    "np.save('all_rewards_P000.npy', all_rewards)\n",
    "np.save('all_terminals_P000.npy', all_terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Args:\n",
    "        observations (numpy.ndarray): N-D array. If the\n",
    "            observation is a vector, the shape should be\n",
    "            `(N, dim_observation)`. If the observations is an image, the shape\n",
    "            should be `(N, C, H, W)`.\n",
    "        actions (numpy.ndarray): N-D array. If the actions-space is\n",
    "            continuous, the shape should be `(N, dim_action)`. If the\n",
    "            action-space is discrete, the shape should be `(N,)`.\n",
    "        rewards (numpy.ndarray): array of scalar rewards. The reward function\n",
    "            should be defined as :math:`r_t = r(s_t, a_t)`.\n",
    "        terminals (numpy.ndarray): array of binary terminal flags.\n",
    "        episode_terminals (numpy.ndarray): array of binary episode terminal\n",
    "            flags. The given data will be splitted based on this flag.\n",
    "            This is useful if you want to specify the non-environment\n",
    "            terminations (e.g. timeout). If ``None``, the episode terminations\n",
    "            match the environment terminations.\n",
    "        discrete_action (bool): flag to use the given actions as discrete\n",
    "            action-space actions. If ``None``, the action type is automatically\n",
    "            determined.\n",
    "    '''\n",
    "cql_dataset = MDPDataset(observations=all_observations,actions=all_actions,rewards=all_rewards,terminals=all_terminals,episode_terminals=all_terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRoundIterator is selected.\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/CQL_20230503011241\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters are saved to d3rlpy_logs/CQL_20230503011241/params.json\u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'action_scaler': None, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'actor_learning_rate': 0.0001, 'actor_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'alpha_learning_rate': 0.0001, 'alpha_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'alpha_threshold': 10.0, 'batch_size': 256, 'conservative_weight': 5.0, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_learning_rate': 0.0003, 'critic_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'gamma': 0.99, 'generated_maxlen': 100000, 'initial_alpha': 1.0, 'initial_temperature': 1.0, 'n_action_samples': 10, 'n_critics': 2, 'n_frames': 1, 'n_steps': 1, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': None, 'soft_q_backup': False, 'tau': 0.005, 'temp_learning_rate': 0.0001, 'temp_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'use_gpu': None, 'algorithm': 'CQL', 'observation_shape': (768,), 'action_size': 7}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004163503646850586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 1/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dcb3bbce9444aeb21327f15cd0ff21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=1 step=4\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007401108741760254, 'time_algorithm_update': 0.13943541049957275, 'temp_loss': 11.497802257537842, 'temp': 0.9997500032186508, 'alpha_loss': -31.219698429107666, 'alpha': 1.0002500414848328, 'critic_loss': 578.8850479125977, 'actor_loss': -4.8624091148376465, 'time_step': 0.14036989212036133}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_4.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00656580924987793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 2/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8d187bb9c64a7b863c28e7fd99e241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=2 step=8\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0008065700531005859, 'time_algorithm_update': 0.13902419805526733, 'temp_loss': 11.686041593551636, 'temp': 0.9993497878313065, 'alpha_loss': -31.282936573028564, 'alpha': 1.0006502270698547, 'critic_loss': 575.037727355957, 'actor_loss': -5.53440248966217, 'time_step': 0.1400248408317566}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m8\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_8.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0062408447265625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 3/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3eb4ce640c4ac5a090505bdc0903b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=3 step=12\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0009879469871520996, 'time_algorithm_update': 0.12402170896530151, 'temp_loss': 11.76022744178772, 'temp': 0.9989491403102875, 'alpha_loss': -31.269726753234863, 'alpha': 1.0010507106781006, 'critic_loss': 574.1525115966797, 'actor_loss': -6.174556493759155, 'time_step': 0.12525659799575806}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m12\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_12.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005036830902099609,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 4/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf938a1680b41e7976867ac32a744e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=4 step=16\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0006661415100097656, 'time_algorithm_update': 0.09896260499954224, 'temp_loss': 11.744263410568237, 'temp': 0.9985483884811401, 'alpha_loss': -31.28003692626953, 'alpha': 1.0014512836933136, 'critic_loss': 573.6416625976562, 'actor_loss': -6.678871273994446, 'time_step': 0.09982997179031372}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m16\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_16.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00444793701171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 5/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd99a8e984d454589f006a1512eea27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=5 step=20\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007225275039672852, 'time_algorithm_update': 0.09355759620666504, 'temp_loss': 11.767021179199219, 'temp': 0.9981476962566376, 'alpha_loss': -31.292337894439697, 'alpha': 1.0018520653247833, 'critic_loss': 572.6839141845703, 'actor_loss': -6.848942160606384, 'time_step': 0.09447461366653442}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_20.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004884958267211914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 6/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93fa836ce114b999716179e730428d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=6 step=24\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007832646369934082, 'time_algorithm_update': 0.09341329336166382, 'temp_loss': 11.763001680374146, 'temp': 0.9977471381425858, 'alpha_loss': -31.296842575073242, 'alpha': 1.002252995967865, 'critic_loss': 572.4057388305664, 'actor_loss': -6.88859748840332, 'time_step': 0.09438925981521606}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m24\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_24.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004637002944946289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 7/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec3a522f46d4d21b623ffce9d7455c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=7 step=28\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m7\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007256269454956055, 'time_algorithm_update': 0.09201222658157349, 'temp_loss': 11.746628046035767, 'temp': 0.9973468035459518, 'alpha_loss': -31.29719638824463, 'alpha': 1.0026541352272034, 'critic_loss': 572.1348724365234, 'actor_loss': -6.813238024711609, 'time_step': 0.09293067455291748}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m28\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_28.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00528717041015625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 8/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f13350669849d096e866e7de2e7712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=8 step=32\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m8\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007138252258300781, 'time_algorithm_update': 0.09319329261779785, 'temp_loss': 11.737781286239624, 'temp': 0.9969467967748642, 'alpha_loss': -31.359646320343018, 'alpha': 1.0030555129051208, 'critic_loss': 571.8306503295898, 'actor_loss': -6.7638561725616455, 'time_step': 0.09409916400909424}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m32\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_32.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004813432693481445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 9/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e3dc233902463cabf8a258601f4167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=9 step=36\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m9\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007060766220092773, 'time_algorithm_update': 0.09556132555007935, 'temp_loss': 11.737273693084717, 'temp': 0.9965471774339676, 'alpha_loss': -31.345335483551025, 'alpha': 1.0034571886062622, 'critic_loss': 571.6585922241211, 'actor_loss': -6.738372325897217, 'time_step': 0.0964612364768982}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m36\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_36.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005864381790161133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 10/10",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617698a23ad8400f8a10ea96edc8e692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-05-03 01:12:45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCQL_20230503011241: epoch=10 step=40\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m10\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0007943511009216309, 'time_algorithm_update': 0.09351634979248047, 'temp_loss': 11.736368417739868, 'temp': 0.9961478263139725, 'alpha_loss': -31.333800792694092, 'alpha': 1.0038590133190155, 'critic_loss': 571.3820266723633, 'actor_loss': -6.799766898155212, 'time_step': 0.09450554847717285}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m40\u001b[0m\n",
      "\u001b[2m2023-05-03 01:12:45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/CQL_20230503011241/model_40.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.0007401108741760254,\n",
       "   'time_algorithm_update': 0.13943541049957275,\n",
       "   'temp_loss': 11.497802257537842,\n",
       "   'temp': 0.9997500032186508,\n",
       "   'alpha_loss': -31.219698429107666,\n",
       "   'alpha': 1.0002500414848328,\n",
       "   'critic_loss': 578.8850479125977,\n",
       "   'actor_loss': -4.8624091148376465,\n",
       "   'time_step': 0.14036989212036133}),\n",
       " (2,\n",
       "  {'time_sample_batch': 0.0008065700531005859,\n",
       "   'time_algorithm_update': 0.13902419805526733,\n",
       "   'temp_loss': 11.686041593551636,\n",
       "   'temp': 0.9993497878313065,\n",
       "   'alpha_loss': -31.282936573028564,\n",
       "   'alpha': 1.0006502270698547,\n",
       "   'critic_loss': 575.037727355957,\n",
       "   'actor_loss': -5.53440248966217,\n",
       "   'time_step': 0.1400248408317566}),\n",
       " (3,\n",
       "  {'time_sample_batch': 0.0009879469871520996,\n",
       "   'time_algorithm_update': 0.12402170896530151,\n",
       "   'temp_loss': 11.76022744178772,\n",
       "   'temp': 0.9989491403102875,\n",
       "   'alpha_loss': -31.269726753234863,\n",
       "   'alpha': 1.0010507106781006,\n",
       "   'critic_loss': 574.1525115966797,\n",
       "   'actor_loss': -6.174556493759155,\n",
       "   'time_step': 0.12525659799575806}),\n",
       " (4,\n",
       "  {'time_sample_batch': 0.0006661415100097656,\n",
       "   'time_algorithm_update': 0.09896260499954224,\n",
       "   'temp_loss': 11.744263410568237,\n",
       "   'temp': 0.9985483884811401,\n",
       "   'alpha_loss': -31.28003692626953,\n",
       "   'alpha': 1.0014512836933136,\n",
       "   'critic_loss': 573.6416625976562,\n",
       "   'actor_loss': -6.678871273994446,\n",
       "   'time_step': 0.09982997179031372}),\n",
       " (5,\n",
       "  {'time_sample_batch': 0.0007225275039672852,\n",
       "   'time_algorithm_update': 0.09355759620666504,\n",
       "   'temp_loss': 11.767021179199219,\n",
       "   'temp': 0.9981476962566376,\n",
       "   'alpha_loss': -31.292337894439697,\n",
       "   'alpha': 1.0018520653247833,\n",
       "   'critic_loss': 572.6839141845703,\n",
       "   'actor_loss': -6.848942160606384,\n",
       "   'time_step': 0.09447461366653442}),\n",
       " (6,\n",
       "  {'time_sample_batch': 0.0007832646369934082,\n",
       "   'time_algorithm_update': 0.09341329336166382,\n",
       "   'temp_loss': 11.763001680374146,\n",
       "   'temp': 0.9977471381425858,\n",
       "   'alpha_loss': -31.296842575073242,\n",
       "   'alpha': 1.002252995967865,\n",
       "   'critic_loss': 572.4057388305664,\n",
       "   'actor_loss': -6.88859748840332,\n",
       "   'time_step': 0.09438925981521606}),\n",
       " (7,\n",
       "  {'time_sample_batch': 0.0007256269454956055,\n",
       "   'time_algorithm_update': 0.09201222658157349,\n",
       "   'temp_loss': 11.746628046035767,\n",
       "   'temp': 0.9973468035459518,\n",
       "   'alpha_loss': -31.29719638824463,\n",
       "   'alpha': 1.0026541352272034,\n",
       "   'critic_loss': 572.1348724365234,\n",
       "   'actor_loss': -6.813238024711609,\n",
       "   'time_step': 0.09293067455291748}),\n",
       " (8,\n",
       "  {'time_sample_batch': 0.0007138252258300781,\n",
       "   'time_algorithm_update': 0.09319329261779785,\n",
       "   'temp_loss': 11.737781286239624,\n",
       "   'temp': 0.9969467967748642,\n",
       "   'alpha_loss': -31.359646320343018,\n",
       "   'alpha': 1.0030555129051208,\n",
       "   'critic_loss': 571.8306503295898,\n",
       "   'actor_loss': -6.7638561725616455,\n",
       "   'time_step': 0.09409916400909424}),\n",
       " (9,\n",
       "  {'time_sample_batch': 0.0007060766220092773,\n",
       "   'time_algorithm_update': 0.09556132555007935,\n",
       "   'temp_loss': 11.737273693084717,\n",
       "   'temp': 0.9965471774339676,\n",
       "   'alpha_loss': -31.345335483551025,\n",
       "   'alpha': 1.0034571886062622,\n",
       "   'critic_loss': 571.6585922241211,\n",
       "   'actor_loss': -6.738372325897217,\n",
       "   'time_step': 0.0964612364768982}),\n",
       " (10,\n",
       "  {'time_sample_batch': 0.0007943511009216309,\n",
       "   'time_algorithm_update': 0.09351634979248047,\n",
       "   'temp_loss': 11.736368417739868,\n",
       "   'temp': 0.9961478263139725,\n",
       "   'alpha_loss': -31.333800792694092,\n",
       "   'alpha': 1.0038590133190155,\n",
       "   'critic_loss': 571.3820266723633,\n",
       "   'actor_loss': -6.799766898155212,\n",
       "   'time_step': 0.09450554847717285})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from d3rlpy.algos import CQL\n",
    "\n",
    "# setup CQL algorithm\n",
    "cql = CQL(use_gpu=False)\n",
    "\n",
    "# split train and test episodes\n",
    "# train_episodes, test_episodes = train_test_split(cql_dataset, test_size=0.25)\n",
    "\n",
    "# start training\n",
    "cql.fit(cql_dataset,\n",
    "        eval_episodes=None,\n",
    "        n_epochs=10,\n",
    "        scorers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All observations shape: (1480, 768)\n",
      "All actions shape: (1480, 7)\n",
      "All rewards shape: (1480,)\n",
      "All terminals shape: (1536,)\n",
      "All observations shape: (2535, 768)\n",
      "All actions shape: (2535, 7)\n",
      "All rewards shape: (2535,)\n",
      "All terminals shape: (2624,)\n",
      "All observations shape: (2651, 768)\n",
      "All actions shape: (2651, 7)\n",
      "All rewards shape: (2651,)\n",
      "All terminals shape: (2752,)\n",
      "All observations shape: (2749, 768)\n",
      "All actions shape: (2749, 7)\n",
      "All rewards shape: (2749,)\n",
      "All terminals shape: (2880,)\n",
      "All observations shape: (2827, 768)\n",
      "All actions shape: (2827, 7)\n",
      "All rewards shape: (2827,)\n",
      "All terminals shape: (3008,)\n",
      "All observations shape: (2935, 768)\n",
      "All actions shape: (2935, 7)\n",
      "All rewards shape: (2935,)\n",
      "All terminals shape: (3136,)\n",
      "All observations shape: (3017, 768)\n",
      "All actions shape: (3017, 7)\n",
      "All rewards shape: (3017,)\n",
      "All terminals shape: (3264,)\n",
      "All observations shape: (3059, 768)\n",
      "All actions shape: (3059, 7)\n",
      "All rewards shape: (3059,)\n",
      "All terminals shape: (3392,)\n",
      "All observations shape: (3083, 768)\n",
      "All actions shape: (3083, 7)\n",
      "All rewards shape: (3083,)\n",
      "All terminals shape: (3520,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from d3rlpy.dataset import Episode, MDPDataset, Transition\n",
    "\n",
    "OBSERVATION_SIZE = 768\n",
    "ACTION_SIZE = 7\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "all_observations = np.empty((0, OBSERVATION_SIZE))\n",
    "all_actions = np.empty((0, ACTION_SIZE))\n",
    "all_rewards = np.empty(0)\n",
    "all_terminals = np.empty(0, dtype=bool)\n",
    "\n",
    "for i in range(0,10):\n",
    "    if i==7:\n",
    "        continue\n",
    "    observation = np.load(f'trajectories/all_observations_P00{i}.npy')\n",
    "    action = np.load(f'trajectories/all_actions_P00{i}.npy')\n",
    "    reward = np.load(f'trajectories/all_rewards_P00{i}.npy')\n",
    "    terminals = np.load(f'trajectories/all_terminals_P00{i}.npy')\n",
    "\n",
    "    all_observations = np.vstack((all_observations, observation))\n",
    "    all_actions = np.vstack((all_actions, action))\n",
    "    all_rewards = np.hstack((all_rewards, reward))\n",
    "    all_terminals = np.hstack((all_terminals, terminals))\n",
    "\n",
    "    print(\"All observations shape:\", all_observations.shape)\n",
    "    print(\"All actions shape:\", all_actions.shape)\n",
    "    print(\"All rewards shape:\", all_rewards.shape)\n",
    "    print(\"All terminals shape:\", all_terminals.shape)\n",
    "cql_dataset = MDPDataset(observations=all_observations,actions=all_actions,rewards=all_rewards,terminals=all_terminals,episode_terminals=all_terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d3rlpy.algos import CQL\n",
    "cql01 = CQL(use_gpu=False)\n",
    "cql01.build_with_dataset(cql_dataset)\n",
    "cql01.load_model('/home/ubuntu/camelmera/models/gym/multimodal/d3rlpy_logs/CQL_20230503011241/model_40.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

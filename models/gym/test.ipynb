{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ply\n",
      "format binary_little_endian 1.0\n",
      "element vertex 54010\n",
      "property float x\n",
      "property float y\n",
      "property float z\n",
      "end_header\n"
     ]
    }
   ],
   "source": [
    "timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from experiment import discount_cumsum\n",
    "\n",
    "def visualize_performance(model, trajectories, start_position, goal_position):\n",
    "        model.eval()\n",
    "\n",
    "        training_positions = []\n",
    "        testing_positions = []\n",
    "\n",
    "        for traj in trajectories:\n",
    "            training_positions.append(traj[\"observations\"][:, -243:-240])  # Extract position information from the last 3 elements of state\n",
    "            start_position = torch.zeros(1, 1, 3)\n",
    "            states = start_position\n",
    "            print(states.shape)\n",
    "            actions = torch.ones(1, 1, 3)*0.01 # change in the future\n",
    "            print(actions)\n",
    "            rewards = -np.linalg.norm(states[0][0] - goal_position) \n",
    "            print(rewards)\n",
    "            \n",
    "            rtg = discount_cumsum(rewards, 0.99)\n",
    "            timesteps = np.arange(0, 1).reshape(1, -1)\n",
    "            for i in range(100):\n",
    "                 with torch.no_grad():\n",
    "                    state_preds,action_preds, reward_preds = model.forward(states, actions, rewards, rtg[:, :-1], timesteps)\n",
    "                    next_state,next_action,next_reward = state_preds[:,-1,:],action_preds[:,-1,:],reward_preds[:,-1,:]\n",
    "                    states = torch.cat((states,next_state),dim=1)\n",
    "                    actions = torch.cat((actions,next_action),dim=1)\n",
    "                    rewards = torch.cat((rewards,next_reward),dim=1)\n",
    "                    rtg = discount_cumsum(rewards, 0.99)\n",
    "                    timesteps = np.arange(0, states.shape[1]).reshape(1, -1)\n",
    "\n",
    "            # (1,100,3)\n",
    "            print(actions.shape)\n",
    "            \n",
    "            vector_to_goal = np.sum(actions.cpu().numpy(),axis=1).reshape(1, -1)+start_position.cpu().numpy()\n",
    "            distance_to_goal = np.linalg.norm(vector_to_goal)\n",
    "\n",
    "            # Calculate testing positions from predicted actions\n",
    "            testing_positions.append(np.cumsum(actions.cpu().numpy(), axis=1)+start_position.cpu().numpy())\n",
    "\n",
    "        testing_positions = np.concatenate(testing_positions, axis=0)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Color code for each training trajectory\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(trajectories)))\n",
    "\n",
    "        # Plot training trajectories\n",
    "        for traj_positions, color in zip(training_positions, colors):\n",
    "            ax.scatter(traj_positions[:, 0], traj_positions[:, 1], traj_positions[:, 2], c='red', alpha=0.1, marker='o', s=2)\n",
    "\n",
    "        # Plot testing trajectories\n",
    "        ax.scatter(testing_positions[:, 0], testing_positions[:, 1], testing_positions[:, 2], c='blue', alpha=0.1, marker='o', s=6)\n",
    "        # Plot start and goal positions\n",
    "        ax.scatter(start_position[0], start_position[1], start_position[2], c='green', marker='s', label='Start', s=100)\n",
    "        ax.scatter(goal_position[0], goal_position[1], goal_position[2], c='purple', marker='*', label='Goal', s=100)\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_observation = (observation-np.mean(observation,dim=-1,keepdims=True))/np.std(observation,dim=-1,keepdims=True)\n",
    "normalized_action = (action-np.mean(action,dim=-1,keepdims=True))/np.std(action,dim=-1,keepdims=True)\n",
    "normalized_reward = (reward-np.mean(reward,dim=-1,keepdims=True))/np.std(reward,dim=-1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import plyfile\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plydata = PlyData.read('000028_lcam_front_lidar.ply')\n",
    "print(plydata)\n",
    "x = plydata['vertex']['x']\n",
    "y = plydata['vertex']['y']\n",
    "z = plydata['vertex']['z']\n",
    "\n",
    "# Load point cloud data from file\n",
    "pcd = o3d.io.read_point_cloud('000028_lcam_front_lidar.ply')\n",
    "points = np.asarray(pcd.points)\n",
    "\n",
    "# Set voxel size\n",
    "voxel_size = 0.1\n",
    "\n",
    "# Voxelization\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=voxel_size)\n",
    "voxels = np.asarray(voxel_grid.get_voxels())\n",
    "\n",
    "# Convert voxel grid to tensor\n",
    "tensor = np.zeros(np.array(voxel_grid.get_voxels()).shape[:3], dtype=np.float32)\n",
    "for voxel in voxels:\n",
    "    voxel_indices = voxel_grid.get_voxel_point_indices(voxel.grid_index)\n",
    "    if len(voxel_indices) == 0:\n",
    "        voxel.color = np.array([0, 0, 0], dtype=np.float32)\n",
    "    else:\n",
    "        voxel_points = points[voxel_indices]\n",
    "        voxel.color = np.mean(voxel_points[:, 3:6], axis=0).astype(np.float32)\n",
    "    tensor[voxel.grid_index] = voxel.color\n",
    "\n",
    "# Reshape tensor to match expected input shape of CNN\n",
    "tensor = np.expand_dims(tensor, axis=0)\n",
    "tensor = np.expand_dims(tensor, axis=1)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54010"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plydata['vertex'].data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_preprocessed_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "from process_data import save_image_pkl, save_lidar_pkl, load_fish_lidar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\\\Users\\\\szxkd\\\\Desktop\\\\mmml\\\\camelmera\\\\models\\\\gym\\\\data\\T1\n",
      "7\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "saved_folder_path = 'C:\\\\\\\\Users\\\\\\\\szxkd\\\\\\\\Desktop\\\\\\\\mmml\\\\\\\\camelmera\\\\\\\\models\\\\\\\\gym\\\\\\\\data'\n",
    "save_image_pkl(saved_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\\\Users\\\\szxkd\\\\Desktop\\\\mmml\\\\camelmera\\\\models\\\\gym\\\\data\\T1\n",
      "7\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "save_lidar_pkl(saved_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = load_preprocessed_data(\"C:\\\\Users\\\\szxkd\\\\Desktop\\\\mmml\\\\camelmera\\\\models\\\\gym\\\\data\\\\T1\\\\image_lcam_fish.pkl\")\n",
    "lidar_tensor = load_preprocessed_data(\"C:\\\\Users\\\\szxkd\\\\Desktop\\\\mmml\\\\camelmera\\\\models\\\\gym\\\\data\\\\T1\\\\lidar_rcam_fish.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor[0].shape)\n",
    "print(lidar_tensor[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# If you have more than 1 trajectory (x trajectories), you need to run this script x times, each time increase the trajectory_index by 1\n",
    "trajectory_index = 0\n",
    "\n",
    "class IMU_Image_Depth_Dataset(Dataset):\n",
    "    def __init__(self, goal_position, load_from_file=False,preprocessed_data_path=None, data_dir=None):\n",
    "        if load_from_file:\n",
    "            if preprocessed_data_path != None and os.path.exists(preprocessed_data_path):\n",
    "                print('Loading preprocessed data from file...')\n",
    "                with open(preprocessed_data_path, 'rb') as f:\n",
    "                    self.datasets = pickle.load(f)\n",
    "            else:\n",
    "                load_from_file = False\n",
    "        if not load_from_file:\n",
    "            if os.path.exists(data_dir):\n",
    "                print('Preprocessing data...')\n",
    "                self.datasets = self.load_data(data_dir, goal_position)\n",
    "                print('Saving preprocessed data to file...')\n",
    "                if preprocessed_data_path == None:\n",
    "                    preprocessed_data_path = os.path.join(data_dir, f\"preprocessed_data_v{trajectory_index}.pkl\")\n",
    "                self.save_preprocessed_data(self.datasets, preprocessed_data_path)\n",
    "            else:\n",
    "                print('Can not get preprocessed data...')\n",
    "\n",
    "    def load_data(self, data_dir, goal_position):\n",
    "        all_datasets = []\n",
    "\n",
    "        for folder in os.listdir(data_dir)[trajectory_index:trajectory_index+1]:\n",
    "            trajectory_folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(trajectory_folder_path):\n",
    "                continue\n",
    "            states = []\n",
    "            actions = []\n",
    "            rewards = []\n",
    "            positions = []\n",
    "            print(f'Processing folder: {trajectory_folder_path}')\n",
    "\n",
    "            # check if contains imu.npy image_lcam_fish.pkl depth_lcam_fish.pkl pose_lcam_front.pkl\n",
    "            imu_npy_path = os.path.join(trajectory_folder_path, \"imu.npy\")\n",
    "            image_pkl_path = os.path.join(trajectory_folder_path, \"image_lcam_fish.pkl\")\n",
    "            depth_pkl_path = os.path.join(trajectory_folder_path, \"depth_lcam_fish.pkl\")\n",
    "            pose_file_path = os.path.join(trajectory_folder_path, 'pose_lcam_front.txt')\n",
    "\n",
    "            if not os.path.exists(imu_npy_path):\n",
    "                print(f\"ERROR: generate {trajectory_folder_path}/imu.npy first\")\n",
    "                continue\n",
    "            if not os.path.exists(image_pkl_path):\n",
    "                print(f\"ERROR: generate {trajectory_folder_path}/image_lcam_fish.pkl first\")\n",
    "                continue\n",
    "            if not os.path.exists(depth_pkl_path):\n",
    "                print(f\"ERROR: generate {trajectory_folder_path}/depth_lcam_fish.pkl first\")\n",
    "                continue\n",
    "            if not os.path.exists(pose_file_path):\n",
    "                print(f\"ERROR: download {trajectory_folder_path}/pose_lcam_front.txt first\")\n",
    "                continue\n",
    "            \n",
    "            print(f'loading {imu_npy_path}...')\n",
    "            imu_data_list = np.load(imu_npy_path)\n",
    "\n",
    "            print(f'loading {image_pkl_path}...')\n",
    "            with open(image_pkl_path, 'rb') as file:\n",
    "                image_list = pickle.load(file)\n",
    "            print(f'loading {depth_pkl_path}...')\n",
    "            with open(depth_pkl_path, 'rb') as file:\n",
    "                depth_list = pickle.load(file)\n",
    "            print(f'loading {pose_file_path}...')\n",
    "            with open(pose_file_path) as f:\n",
    "                for line in f.readlines():\n",
    "                    values = line.strip().split()\n",
    "                    x, y, z = map(float, values[:3])\n",
    "                    positions.append(np.array([x, y, z]))\n",
    "            positions = np.array(positions)  # Convert positions to a numpy array\n",
    "\n",
    "            assert len(image_list) == len(depth_list)\n",
    "            assert len(image_list)-1 == imu_data_list.shape[0]\n",
    "            assert len(image_list) == positions.shape[0]\n",
    "\n",
    "            model_name = 'vit_base_patch16_224'\n",
    "            vit_model = timm.create_model(model_name, pretrained=True)\n",
    "            vit_model.eval()\n",
    "\n",
    "            image_pca = PCA(n_components=36)\n",
    "            depth_pca = PCA(n_components=36)\n",
    "\n",
    "            for idx in tqdm(range(len(image_list)-1)):\n",
    "                img_batch = image_list[idx]\n",
    "                depth_batch = depth_list[idx]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    img_embedding = vit_model.forward_features(img_batch) # last_hidden_state of the ViT model\n",
    "                    img_embedding = img_embedding.reshape(197, 768)\n",
    "                    image_pca.fit(img_embedding)\n",
    "                    img_embedding = image_pca.transform(img_embedding) # (197, 36)\n",
    "                    img_embedding = img_embedding.reshape(-1) # shape: (7092,)\n",
    "\n",
    "                    depth_embedding = vit_model.forward_features(depth_batch) # last_hidden_state of the ViT model\n",
    "                    depth_embedding = depth_embedding.reshape(197, 768)\n",
    "                    depth_pca.fit(depth_embedding)\n",
    "                    depth_embedding = depth_pca.transform(depth_embedding) #\n",
    "                    depth_embedding = depth_embedding.reshape(-1) # shape: (7092,)\n",
    "                state = np.hstack((img_embedding,depth_embedding, imu_data_list[idx], positions[idx]))  # Stack the embeddings and positions horizontally\n",
    "                states.append(state)\n",
    "\n",
    "                if idx > 0:\n",
    "                    action = positions[idx] - positions[idx - 1]\n",
    "                    actions.append(action)\n",
    "\n",
    "                    reward = -np.linalg.norm(positions[idx] - goal_position) # Labeling Reward as negative distance to goal\n",
    "                    rewards.append(reward)\n",
    "            all_datasets.append({\n",
    "                      'observations': np.array(states),\n",
    "                      'actions': np.array(actions),\n",
    "                      'rewards': np.array(rewards)\n",
    "                      })\n",
    "            print(\"all_datasets len\", len(all_datasets))\n",
    "        return all_datasets\n",
    "\n",
    "\n",
    "    def save_preprocessed_data(self, datasets, preprocessed_data_path):\n",
    "        with open(preprocessed_data_path, 'wb') as f:\n",
    "          pickle.dump(datasets, f)\n",
    "          print(f'Saved preprocessed data {len(datasets)} to {preprocessed_data_path}')\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of images\n",
    "        return len(self.datasets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.datasets[idx]\n",
    "\n",
    "# Example usage of the custom dataset and dataloader\n",
    "# Define the image directory and labels\n",
    "data_dir = '/content/drive/MyDrive/tartanairv2filtered'\n",
    "goal_position = np.array([10, 10, 10])  \n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "dataset = IMU_Image_Depth_Dataset(goal_position=goal_position, load_from_file=False, preprocessed_data_path=None, data_dir=data_dir)\n",
    "\n",
    "# Create a dataloader for batching and shuffling\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Iterate over the dataloader during training\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    # Perform training operations on the batch of data\n",
    "    print(batch_idx)\n",
    "    print(len(data))\n",
    "    print(data['observations'].shape)\n",
    "    print(data['actions'].shape)\n",
    "    print(data['rewards'].shape)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11f074da79a2560deeae476e47853a185cbf0a9e560fbec7d341528340d444c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
